"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from cribl.types import BaseModel
from enum import Enum
import pydantic
from typing import Any, List, Optional
from typing_extensions import Annotated, NotRequired, TypedDict


class InputWefType(str, Enum):
    WEF = "wef"


class InputWefConnectionsTypedDict(TypedDict):
    output: str
    pipeline: NotRequired[str]


class InputWefConnections(BaseModel):
    output: str

    pipeline: Optional[str] = None


class InputWefMode(str, Enum):
    r"""With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine."""

    SMART = "smart"
    ALWAYS = "always"


class InputWefCompression(str, Enum):
    r"""Codec to use to compress the persisted data"""

    NONE = "none"
    GZIP = "gzip"


class InputWefPqTypedDict(TypedDict):
    mode: NotRequired[InputWefMode]
    r"""With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine."""
    max_buffer_size: NotRequired[float]
    r"""The maximum number of events to hold in memory before writing the events to disk"""
    commit_frequency: NotRequired[float]
    r"""The number of events to send downstream before committing that Stream has read them"""
    max_file_size: NotRequired[str]
    r"""The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc."""
    max_size: NotRequired[str]
    r"""The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc."""
    path: NotRequired[str]
    r"""The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>"""
    compress: NotRequired[InputWefCompression]
    r"""Codec to use to compress the persisted data"""


class InputWefPq(BaseModel):
    mode: Optional[InputWefMode] = InputWefMode.ALWAYS
    r"""With Smart mode, PQ will write events to the filesystem only when it detects backpressure from the processing engine. With Always On mode, PQ will always write events directly to the queue before forwarding them to the processing engine."""

    max_buffer_size: Annotated[
        Optional[float], pydantic.Field(alias="maxBufferSize")
    ] = 1000
    r"""The maximum number of events to hold in memory before writing the events to disk"""

    commit_frequency: Annotated[
        Optional[float], pydantic.Field(alias="commitFrequency")
    ] = 42
    r"""The number of events to send downstream before committing that Stream has read them"""

    max_file_size: Annotated[Optional[str], pydantic.Field(alias="maxFileSize")] = (
        "1 MB"
    )
    r"""The maximum size to store in each queue file before closing and optionally compressing. Enter a numeral with units of KB, MB, etc."""

    max_size: Annotated[Optional[str], pydantic.Field(alias="maxSize")] = "5GB"
    r"""The maximum disk space that the queue can consume (as an average per Worker Process) before queueing stops. Enter a numeral with units of KB, MB, etc."""

    path: Optional[str] = "$CRIBL_HOME/state/queues"
    r"""The location for the persistent queue files. To this field's value, the system will append: /<worker-id>/inputs/<input-id>"""

    compress: Optional[InputWefCompression] = InputWefCompression.NONE
    r"""Codec to use to compress the persisted data"""


class InputWefAuthenticationMethod(str, Enum):
    r"""Method by which to authenticate incoming client connections."""

    CLIENT_CERT = "clientCert"
    KERBEROS = "kerberos"


class InputWefMinimumTLSVersion(str, Enum):
    r"""Minimum TLS version to accept from connections."""

    TL_SV1 = "TLSv1"
    TL_SV1_1 = "TLSv1.1"
    TL_SV1_2 = "TLSv1.2"
    TL_SV1_3 = "TLSv1.3"


class InputWefMaximumTLSVersion(str, Enum):
    r"""Maximum TLS version to accept from connections"""

    TL_SV1 = "TLSv1"
    TL_SV1_1 = "TLSv1.1"
    TL_SV1_2 = "TLSv1.2"
    TL_SV1_3 = "TLSv1.3"


class MTLSSettingsTypedDict(TypedDict):
    priv_key_path: str
    r"""Path on server containing the private key to use. PEM format. Can reference $ENV_VARS."""
    cert_path: str
    r"""Path on server containing certificates to use. PEM format. Can reference $ENV_VARS."""
    ca_path: str
    r"""Server path containing CA certificates (in PEM format) to use. Can reference $ENV_VARS. If multiple certificates are present in a .pem, each must directly certify the one preceding it."""
    disabled: NotRequired[bool]
    r"""Enable TLS"""
    reject_unauthorized: NotRequired[bool]
    r"""Required for WEF certificate authentication."""
    request_cert: NotRequired[bool]
    r"""Required for WEF certificate authentication."""
    certificate_name: NotRequired[str]
    r"""Name of the predefined certificate."""
    passphrase: NotRequired[str]
    r"""Passphrase to use to decrypt private key."""
    common_name_regex: NotRequired[str]
    r"""Regex matching allowable common names in peer certificates' subject attribute."""
    min_version: NotRequired[InputWefMinimumTLSVersion]
    r"""Minimum TLS version to accept from connections."""
    max_version: NotRequired[InputWefMaximumTLSVersion]
    r"""Maximum TLS version to accept from connections"""
    ocsp_check: NotRequired[bool]
    r"""Enable OCSP check of certificate"""
    keytab: NotRequired[Any]
    principal: NotRequired[Any]
    ocsp_check_fail_close: NotRequired[bool]
    r"""If enabled, checks will fail on any OCSP error. Otherwise, checks will fail only when a certificate is revoked, ignoring other errors."""


class MTLSSettings(BaseModel):
    priv_key_path: Annotated[str, pydantic.Field(alias="privKeyPath")]
    r"""Path on server containing the private key to use. PEM format. Can reference $ENV_VARS."""

    cert_path: Annotated[str, pydantic.Field(alias="certPath")]
    r"""Path on server containing certificates to use. PEM format. Can reference $ENV_VARS."""

    ca_path: Annotated[str, pydantic.Field(alias="caPath")]
    r"""Server path containing CA certificates (in PEM format) to use. Can reference $ENV_VARS. If multiple certificates are present in a .pem, each must directly certify the one preceding it."""

    disabled: Optional[bool] = False
    r"""Enable TLS"""

    reject_unauthorized: Annotated[
        Optional[bool], pydantic.Field(alias="rejectUnauthorized")
    ] = True
    r"""Required for WEF certificate authentication."""

    request_cert: Annotated[Optional[bool], pydantic.Field(alias="requestCert")] = True
    r"""Required for WEF certificate authentication."""

    certificate_name: Annotated[
        Optional[str], pydantic.Field(alias="certificateName")
    ] = None
    r"""Name of the predefined certificate."""

    passphrase: Optional[str] = None
    r"""Passphrase to use to decrypt private key."""

    common_name_regex: Annotated[
        Optional[str], pydantic.Field(alias="commonNameRegex")
    ] = "/.*/"
    r"""Regex matching allowable common names in peer certificates' subject attribute."""

    min_version: Annotated[
        Optional[InputWefMinimumTLSVersion], pydantic.Field(alias="minVersion")
    ] = None
    r"""Minimum TLS version to accept from connections."""

    max_version: Annotated[
        Optional[InputWefMaximumTLSVersion], pydantic.Field(alias="maxVersion")
    ] = None
    r"""Maximum TLS version to accept from connections"""

    ocsp_check: Annotated[Optional[bool], pydantic.Field(alias="ocspCheck")] = False
    r"""Enable OCSP check of certificate"""

    keytab: Optional[Any] = None

    principal: Optional[Any] = None

    ocsp_check_fail_close: Annotated[
        Optional[bool], pydantic.Field(alias="ocspCheckFailClose")
    ] = False
    r"""If enabled, checks will fail on any OCSP error. Otherwise, checks will fail only when a certificate is revoked, ignoring other errors."""


class InputWefFormat(str, Enum):
    r"""Content format in which the endpoint should deliver events."""

    RAW = "Raw"
    RENDERED_TEXT = "RenderedText"


class QueryBuilderMode(str, Enum):
    r"""Select the query builder mode."""

    SIMPLE = "simple"
    XML = "xml"


class InputWefSubscriptionsMetadataTypedDict(TypedDict):
    name: str
    value: str
    r"""JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)"""


class InputWefSubscriptionsMetadata(BaseModel):
    name: str

    value: str
    r"""JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)"""


class SubscriptionsModelTypedDict(TypedDict):
    subscription_name: str
    r"""Friendly name for this subscription."""
    targets: List[str]
    r"""Enter the DNS names of the endpoints that should forward these events. You may use wildcards, for example: *.mydomain.com"""
    version: NotRequired[str]
    r"""Version UUID for this subscription. If any subscription parameters are modified, this value will change."""
    content_format: NotRequired[InputWefFormat]
    r"""Content format in which the endpoint should deliver events."""
    heartbeat_interval: NotRequired[float]
    r"""Maximum time (in seconds) between endpoint checkins before considering it unavailable."""
    batch_timeout: NotRequired[float]
    r"""Interval (in seconds) over which the endpoint should collect events before sending them to Stream."""
    read_existing_events: NotRequired[bool]
    r"""Set to Yes if a newly-subscribed endpoint should send previously existing events. Set to No to only receive new events"""
    send_bookmarks: NotRequired[bool]
    r"""If toggled to Yes, @{product} will keep track of which events have been received, resuming from that point after a re-subscription. This setting takes precedence over 'Read existing events' -- see the documentation for details."""
    compress: NotRequired[bool]
    r"""If toggled to Yes, Stream will receive compressed events from the source."""
    locale: NotRequired[str]
    r"""The RFC-3066 locale the Windows clients should use when sending events. Defaults to \"en-US\"."""
    query_selector: NotRequired[QueryBuilderMode]
    r"""Select the query builder mode."""
    metadata: NotRequired[List[InputWefSubscriptionsMetadataTypedDict]]
    r"""Fields to add to events ingested under this subscription"""


class SubscriptionsModel(BaseModel):
    subscription_name: Annotated[str, pydantic.Field(alias="subscriptionName")]
    r"""Friendly name for this subscription."""

    targets: List[str]
    r"""Enter the DNS names of the endpoints that should forward these events. You may use wildcards, for example: *.mydomain.com"""

    version: Optional[str] = None
    r"""Version UUID for this subscription. If any subscription parameters are modified, this value will change."""

    content_format: Annotated[
        Optional[InputWefFormat], pydantic.Field(alias="contentFormat")
    ] = InputWefFormat.RAW
    r"""Content format in which the endpoint should deliver events."""

    heartbeat_interval: Annotated[
        Optional[float], pydantic.Field(alias="heartbeatInterval")
    ] = 60
    r"""Maximum time (in seconds) between endpoint checkins before considering it unavailable."""

    batch_timeout: Annotated[Optional[float], pydantic.Field(alias="batchTimeout")] = 60
    r"""Interval (in seconds) over which the endpoint should collect events before sending them to Stream."""

    read_existing_events: Annotated[
        Optional[bool], pydantic.Field(alias="readExistingEvents")
    ] = False
    r"""Set to Yes if a newly-subscribed endpoint should send previously existing events. Set to No to only receive new events"""

    send_bookmarks: Annotated[Optional[bool], pydantic.Field(alias="sendBookmarks")] = (
        True
    )
    r"""If toggled to Yes, @{product} will keep track of which events have been received, resuming from that point after a re-subscription. This setting takes precedence over 'Read existing events' -- see the documentation for details."""

    compress: Optional[bool] = True
    r"""If toggled to Yes, Stream will receive compressed events from the source."""

    locale: Optional[str] = "en-US"
    r"""The RFC-3066 locale the Windows clients should use when sending events. Defaults to \"en-US\"."""

    query_selector: Annotated[
        Optional[QueryBuilderMode], pydantic.Field(alias="querySelector")
    ] = QueryBuilderMode.SIMPLE
    r"""Select the query builder mode."""

    metadata: Optional[List[InputWefSubscriptionsMetadata]] = None
    r"""Fields to add to events ingested under this subscription"""


class InputWefMetadataTypedDict(TypedDict):
    name: str
    value: str
    r"""JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)"""


class InputWefMetadata(BaseModel):
    name: str

    value: str
    r"""JavaScript expression to compute field's value, enclosed in quotes or backticks. (Can evaluate to a constant.)"""


class InputWefTypedDict(TypedDict):
    subscriptions: List[SubscriptionsModelTypedDict]
    r"""Subscriptions to events on forwarding endpoints."""
    id: NotRequired[str]
    r"""Unique ID for this input"""
    type: NotRequired[InputWefType]
    disabled: NotRequired[bool]
    pipeline: NotRequired[str]
    r"""Pipeline to process data from this Source before sending it through the Routes"""
    send_to_routes: NotRequired[bool]
    r"""Select whether to send data to Routes, or directly to Destinations."""
    environment: NotRequired[str]
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""
    pq_enabled: NotRequired[bool]
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""
    streamtags: NotRequired[List[str]]
    r"""Tags for filtering and grouping in @{product}"""
    connections: NotRequired[List[InputWefConnectionsTypedDict]]
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""
    pq: NotRequired[InputWefPqTypedDict]
    host: NotRequired[str]
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""
    port: NotRequired[float]
    r"""Port to listen on"""
    auth_method: NotRequired[InputWefAuthenticationMethod]
    r"""Method by which to authenticate incoming client connections."""
    tls: NotRequired[MTLSSettingsTypedDict]
    max_active_req: NotRequired[float]
    r"""Maximum number of active requests per Worker Process. Use 0 for unlimited."""
    max_requests_per_socket: NotRequired[int]
    r"""Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited)."""
    enable_proxy_header: NotRequired[bool]
    r"""Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address"""
    capture_headers: NotRequired[bool]
    r"""Add request headers to events in the __headers field"""
    keep_alive_timeout: NotRequired[float]
    r"""After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.)."""
    enable_health_check: NotRequired[bool]
    r"""Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy"""
    ip_allowlist_regex: NotRequired[str]
    r"""Messages from matched IP addresses will be processed, unless also matched by the denylist."""
    ip_denylist_regex: NotRequired[str]
    r"""Messages from matched IP addresses will be ignored. This takes precedence over the allowlist."""
    socket_timeout: NotRequired[float]
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0."""
    ca_fingerprint: NotRequired[str]
    r"""SHA1 fingerprint expected by the client, if it does not match the first certificate in the configured CA chain"""
    keytab: NotRequired[str]
    r"""Path to the keytab file containing the service principal credentials. @{product} will use `/etc/krb5.keytab` if not provided."""
    principal: NotRequired[str]
    r"""Kerberos principal used for authentication, typically in the form HTTP/<hostname>@<REALM>."""
    allow_machine_id_mismatch: NotRequired[bool]
    r"""Allow events to be ingested even if their MachineID does not match the client certificate CN."""
    metadata: NotRequired[List[InputWefMetadataTypedDict]]
    r"""Fields to add to events from this input"""
    description: NotRequired[str]


class InputWef(BaseModel):
    subscriptions: List[SubscriptionsModel]
    r"""Subscriptions to events on forwarding endpoints."""

    id: Optional[str] = None
    r"""Unique ID for this input"""

    type: Optional[InputWefType] = None

    disabled: Optional[bool] = False

    pipeline: Optional[str] = None
    r"""Pipeline to process data from this Source before sending it through the Routes"""

    send_to_routes: Annotated[Optional[bool], pydantic.Field(alias="sendToRoutes")] = (
        True
    )
    r"""Select whether to send data to Routes, or directly to Destinations."""

    environment: Optional[str] = None
    r"""Optionally, enable this config only on a specified Git branch. If empty, will be enabled everywhere."""

    pq_enabled: Annotated[Optional[bool], pydantic.Field(alias="pqEnabled")] = False
    r"""Use a disk queue to minimize data loss when connected services block. See [Cribl Docs](https://docs.cribl.io/stream/persistent-queues) for PQ defaults (Cribl-managed Cloud Workers) and configuration options (on-prem and hybrid Workers)."""

    streamtags: Optional[List[str]] = None
    r"""Tags for filtering and grouping in @{product}"""

    connections: Optional[List[InputWefConnections]] = None
    r"""Direct connections to Destinations, and optionally via a Pipeline or a Pack"""

    pq: Optional[InputWefPq] = None

    host: Optional[str] = "0.0.0.0"
    r"""Address to bind on. Defaults to 0.0.0.0 (all addresses)."""

    port: Optional[float] = 5986
    r"""Port to listen on"""

    auth_method: Annotated[
        Optional[InputWefAuthenticationMethod], pydantic.Field(alias="authMethod")
    ] = InputWefAuthenticationMethod.CLIENT_CERT
    r"""Method by which to authenticate incoming client connections."""

    tls: Optional[MTLSSettings] = None

    max_active_req: Annotated[Optional[float], pydantic.Field(alias="maxActiveReq")] = (
        256
    )
    r"""Maximum number of active requests per Worker Process. Use 0 for unlimited."""

    max_requests_per_socket: Annotated[
        Optional[int], pydantic.Field(alias="maxRequestsPerSocket")
    ] = 0
    r"""Maximum number of requests per socket before @{product} instructs the client to close the connection. Default is 0 (unlimited)."""

    enable_proxy_header: Annotated[
        Optional[bool], pydantic.Field(alias="enableProxyHeader")
    ] = False
    r"""Enable when clients are connecting through a proxy that supports the x-forwarded-for header to keep the client's original IP address on the event instead of the proxy's IP address"""

    capture_headers: Annotated[
        Optional[bool], pydantic.Field(alias="captureHeaders")
    ] = False
    r"""Add request headers to events in the __headers field"""

    keep_alive_timeout: Annotated[
        Optional[float], pydantic.Field(alias="keepAliveTimeout")
    ] = 90
    r"""After the last response is sent, @{product} will wait this long for additional data before closing the socket connection. Minimum 1 sec.; maximum 600 sec. (10 min.)."""

    enable_health_check: Annotated[
        Optional[bool], pydantic.Field(alias="enableHealthCheck")
    ] = False
    r"""Enable to expose the /cribl_health endpoint, which returns 200 OK when this Source is healthy"""

    ip_allowlist_regex: Annotated[
        Optional[str], pydantic.Field(alias="ipAllowlistRegex")
    ] = "/.*/"
    r"""Messages from matched IP addresses will be processed, unless also matched by the denylist."""

    ip_denylist_regex: Annotated[
        Optional[str], pydantic.Field(alias="ipDenylistRegex")
    ] = "/^$/"
    r"""Messages from matched IP addresses will be ignored. This takes precedence over the allowlist."""

    socket_timeout: Annotated[
        Optional[float], pydantic.Field(alias="socketTimeout")
    ] = 0
    r"""How long @{product} should wait before assuming that an inactive socket has timed out. To wait forever, set to 0."""

    ca_fingerprint: Annotated[Optional[str], pydantic.Field(alias="caFingerprint")] = (
        None
    )
    r"""SHA1 fingerprint expected by the client, if it does not match the first certificate in the configured CA chain"""

    keytab: Optional[str] = None
    r"""Path to the keytab file containing the service principal credentials. @{product} will use `/etc/krb5.keytab` if not provided."""

    principal: Optional[str] = None
    r"""Kerberos principal used for authentication, typically in the form HTTP/<hostname>@<REALM>."""

    allow_machine_id_mismatch: Annotated[
        Optional[bool], pydantic.Field(alias="allowMachineIdMismatch")
    ] = False
    r"""Allow events to be ingested even if their MachineID does not match the client certificate CN."""

    metadata: Optional[List[InputWefMetadata]] = None
    r"""Fields to add to events from this input"""

    description: Optional[str] = None
